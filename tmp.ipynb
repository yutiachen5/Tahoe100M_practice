{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8493e0d-d89c-42a4-97fd-6cb6d45096b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 15:00:38.326570: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-05 15:00:39.915859: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-05 15:00:40.396963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-05 15:00:40.698376: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-05 15:00:40.764275: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 15:00:41.900961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-05 15:00:47.113528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ab93345d1d4304abf77c88c5b031da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c924a29eb75447d4b239ee283055cd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "smiles_tokenizer = AutoTokenizer.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "smiles_encoder = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9910593-4c30-4e3a-8919-61cded8bccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles=['C1=CC2=C(C(=C1)O)N=CC=C2', 'C1=CC2=C(C(=C1)O)N=CC=C2HHHHHHHH', 'CCCCCCCOOOOOOOOOHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH']\n",
    "input_id = smiles_tokenizer(smiles, padding=True, return_tensors=\"pt\")['input_ids']\n",
    "attention_mask = smiles_tokenizer(smiles, padding=True, return_tensors=\"pt\")['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9f7e2ac-8af8-457e-9ce5-ffc9cc974bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4372,  1.2647,  0.1617,  ..., -0.8632, -0.2230,  2.4517],\n",
       "         [ 0.4037, -0.9196, -0.7497,  ...,  0.0367,  1.0902, -0.7634],\n",
       "         [-0.2758,  2.3355, -0.1460,  ..., -0.2220, -0.5248,  0.5903],\n",
       "         ...,\n",
       "         [ 0.6561,  0.5836, -0.3090,  ..., -0.9481, -0.3316,  1.8215],\n",
       "         [ 0.6561,  0.5836, -0.3090,  ..., -0.9481, -0.3316,  1.8215],\n",
       "         [ 0.6561,  0.5836, -0.3090,  ..., -0.9481, -0.3316,  1.8215]],\n",
       "\n",
       "        [[ 0.6787,  0.7598,  0.6292,  ..., -0.6448, -0.4910,  1.9773],\n",
       "         [ 0.7871, -0.9847, -0.5308,  ..., -0.0184,  0.9848, -0.6030],\n",
       "         [-0.1434,  2.0068, -0.1891,  ..., -0.1338, -0.6584,  0.7653],\n",
       "         ...,\n",
       "         [ 0.5573, -0.1238, -0.0333,  ..., -0.8364, -0.7609,  1.8630],\n",
       "         [ 0.5573, -0.1238, -0.0333,  ..., -0.8364, -0.7609,  1.8630],\n",
       "         [ 0.5573, -0.1238, -0.0333,  ..., -0.8364, -0.7609,  1.8630]],\n",
       "\n",
       "        [[ 0.8735, -0.5985, -1.3702,  ..., -1.0582, -0.0375, -0.2567],\n",
       "         [ 1.4015, -0.9155, -0.0170,  ..., -0.3017,  1.3377, -0.9626],\n",
       "         [ 1.1237, -2.0465, -1.7222,  ..., -0.2269,  0.8797, -0.1262],\n",
       "         ...,\n",
       "         [-0.0856, -0.0028,  0.0324,  ..., -1.0217, -1.4084,  0.0237],\n",
       "         [-1.3017,  0.7641,  0.2650,  ..., -0.8706, -0.4747, -0.0957],\n",
       "         [ 0.7750, -0.4295, -0.5249,  ..., -0.9926,  0.3051, -0.2051]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.1774,  0.3218, -0.7659,  ..., -0.6894,  0.4542, -0.5937],\n",
       "        [ 0.4413,  0.4500, -0.2882,  ..., -0.7188, -0.2055, -0.5256],\n",
       "        [ 0.4879,  0.0610,  0.1293,  ..., -0.7812,  0.3620,  0.1091]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_encoder(input_ids=input_id, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "047f42c1-a8c3-463a-ab5a-200af05e8fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 46, 768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_encoder(input_ids=input_id, attention_mask=attention_mask).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9da58e0-b186-4b6f-9e77-3009cae501ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb0b1667-2423-46a5-91b3-7485b7fd86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 46])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6258441-fb89-4edb-b219-61b83fedcfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"seyonec/ChemBERTa-zinc-base-v1\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 767\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_encoder.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d89329d-9bf8-4751-be9a-1ce02a321a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4977-9a9c-4ef1-a8ae-337a4dfdb34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94427d-6ee1-4098-b484-a9316ecea1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
