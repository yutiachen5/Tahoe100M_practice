dcc-core-gpu-41
Sun Jun  8 13:36:55 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 5000 Ada Gene...    On  |   00000000:13:00.0 Off |                  Off |
| 30%   17C    P8             16W /  250W |       2MiB /  32760MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
loaded 330517 observations
number of unique genes: 47278
Transformer(
  (emb_gene): Embedding(47278, 128)
  (proj_expression): Linear(in_features=1, out_features=128, bias=True)
  (proj_gene_input): Linear(in_features=128, out_features=512, bias=True)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (linear1): Linear(in_features=512, out_features=512, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=512, out_features=512, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (proj_smiles_input): Linear(in_features=768, out_features=512, bias=True)
  (regression_head): Sequential(
    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ReLU()
    (4): Dropout(p=0.1, inplace=False)
    (5): Linear(in_features=256, out_features=1, bias=True)
  )
)
number of params:  11378177
number of trainable params:  11378177
training...
Epoch [1/100]  Train Loss: 3.0660  Val Loss: 2.7457
Epoch [2/100]  Train Loss: 2.7958  Val Loss: 2.7026
Epoch [3/100]  Train Loss: 2.7560  Val Loss: 2.6510
Epoch [4/100]  Train Loss: 2.2879  Val Loss: 2.1615
Epoch [5/100]  Train Loss: 1.8987  Val Loss: 1.6720
Epoch [6/100]  Train Loss: 1.7057  Val Loss: 1.6414
Epoch [7/100]  Train Loss: 1.6087  Val Loss: 1.5017
Epoch [8/100]  Train Loss: 1.5320  Val Loss: 1.7012
Epoch [9/100]  Train Loss: 1.4769  Val Loss: 1.5054
Epoch [10/100]  Train Loss: 1.4242  Val Loss: 1.4393
Epoch [11/100]  Train Loss: 1.3707  Val Loss: 1.3543
Epoch [12/100]  Train Loss: 1.2927  Val Loss: 1.2229
Epoch [13/100]  Train Loss: 1.1931  Val Loss: 1.1164
Epoch [14/100]  Train Loss: 1.0827  Val Loss: 0.9530
Epoch [15/100]  Train Loss: 0.9609  Val Loss: 0.8359
Epoch [16/100]  Train Loss: 0.8514  Val Loss: 0.7755
Epoch [17/100]  Train Loss: 0.7559  Val Loss: 0.6803
Epoch [18/100]  Train Loss: 0.6806  Val Loss: 0.7193
Epoch [19/100]  Train Loss: 0.6026  Val Loss: 0.5075
Epoch [20/100]  Train Loss: 0.5301  Val Loss: 0.4704
Epoch [21/100]  Train Loss: 0.4830  Val Loss: 0.5017
Epoch [22/100]  Train Loss: 0.4561  Val Loss: 0.4462
Epoch [23/100]  Train Loss: 0.4019  Val Loss: 0.4528
Epoch [24/100]  Train Loss: 0.3829  Val Loss: 0.4600
Epoch [25/100]  Train Loss: 0.3551  Val Loss: 0.3149
Epoch [26/100]  Train Loss: 0.3311  Val Loss: 0.2626
Epoch [27/100]  Train Loss: 0.3150  Val Loss: 0.5187
Epoch [28/100]  Train Loss: 0.3047  Val Loss: 0.2661
Epoch [29/100]  Train Loss: 0.2934  Val Loss: 0.2860
Training complete. Best validation loss: 0.2626
predicting...
MSE: 0.2604, PCC: 0.9849, SCC: 0.9855
model saved to /hpc/home/yc583/Tahoe100M_practice/saved_mdls/ic50_predictor.pth
Elapsed time: 1748943353.9 hours
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrun_s_200[0m at: [34mhttps://wandb.ai/tecchk-cyt-duke-university/Tahoe/runs/kns0lcmx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250608_133709-kns0lcmx/logs[0m
